{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_model(num_classes):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_classes: number of classes\n",
    "    Returns:\n",
    "        model: torchvision model\n",
    "    \"\"\"\n",
    "\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "class TACODataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 이미지가 있는 디렉토리 경로\n",
    "            annotation_file (string): annotations_X_train.json 또는 annotations_X_test.json 파일 경로\n",
    "            transform (callable, optional): 이미지에 적용할 변환\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco = json.load(f)\n",
    "\n",
    "        # Create category mapping\n",
    "        self.cat_ids = {}\n",
    "        self.cat_id_to_label = {}\n",
    "        for i, cat in enumerate(self.coco['categories'], 1):  # 1부터 시작 (0은 배경)\n",
    "            self.cat_ids[cat['id']] = cat['name']\n",
    "            self.cat_id_to_label[cat['id']] = i\n",
    "\n",
    "        # Get all valid image ids\n",
    "        self.ids = []\n",
    "        for img in self.coco['images']:\n",
    "            if os.path.exists(os.path.join(self.root_dir, img['file_name'])):\n",
    "                self.ids.append(img['id'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_info = next(img for img in self.coco['images'] if img['id'] == img_id)\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.root_dir, img_info['file_name'])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Get annotations\n",
    "        anns = [ann for ann in self.coco['annotations'] if ann['image_id'] == img_id]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            boxes.append([\n",
    "                bbox[0],\n",
    "                bbox[1],\n",
    "                bbox[0] + bbox[2],\n",
    "                bbox[1] + bbox[3]\n",
    "            ])\n",
    "            # Convert category_id to sequential label\n",
    "            labels.append(self.cat_id_to_label[ann['category_id']])\n",
    "\n",
    "        # Handle images without annotations\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([img_id])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': image_id,\n",
    "            'area': area,\n",
    "            'iscrowd': iscrowd\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self.cat_ids) + 1  # +1 for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.ipynb\n",
    "\n",
    "# 1. 필요한 라이브러리 임포트\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# 2. collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def train(args):\n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 모든 round의 데이터셋과 데이터로더 준비\n",
    "    train_datasets = []\n",
    "    train_loaders = []\n",
    "    test_datasets = []\n",
    "    test_loaders = []\n",
    "\n",
    "    for round_num in range(args.num_rounds):\n",
    "        # Train dataset/loader\n",
    "        train_dataset = TACODataset(\n",
    "            root_dir=args.data_dir,\n",
    "            annotation_file=os.path.join(args.data_dir, f'annotations_{round_num}_train.json')\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        train_datasets.append(train_dataset)\n",
    "        train_loaders.append(train_loader)\n",
    "\n",
    "        # Test dataset/loader\n",
    "        test_dataset = TACODataset(\n",
    "            root_dir=args.data_dir,\n",
    "            annotation_file=os.path.join(args.data_dir, f'annotations_{round_num}_test.json')\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        test_datasets.append(test_dataset)\n",
    "        test_loaders.append(test_loader)\n",
    "\n",
    "    # Model 초기화\n",
    "    model = get_model(train_datasets[0].num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.SGD(params, lr=args.lr, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                  step_size=3,\n",
    "                                                  gamma=0.1)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        total_batches = 0\n",
    "\n",
    "        # 각 epoch에서 모든 round의 데이터로 학습\n",
    "        for round_num, train_loader in enumerate(train_loaders):\n",
    "            round_loss = 0\n",
    "\n",
    "            for i, (images, targets) in enumerate(train_loader):\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                round_loss += losses.item()\n",
    "                epoch_loss += losses.item()\n",
    "                total_batches += 1\n",
    "\n",
    "                if i % 50 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/{args.epochs}], Round [{round_num}], '\n",
    "                          f'Step [{i}/{len(train_loader)}], Loss: {losses.item():.4f}')\n",
    "\n",
    "            avg_round_loss = round_loss / len(train_loader)\n",
    "            print(f'Epoch [{epoch+1}/{args.epochs}], Round [{round_num}] '\n",
    "                  f'Average Loss: {avg_round_loss:.4f}')\n",
    "\n",
    "        # 에폭의 평균 손실 계산\n",
    "        avg_epoch_loss = epoch_loss / total_batches\n",
    "        print(f'Epoch [{epoch+1}/{args.epochs}] Complete, '\n",
    "              f'Average Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        if (epoch + 1) % args.save_freq == 0:\n",
    "            checkpoint_path = os.path.join(args.output_dir,\n",
    "                                         f'model_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_epoch_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f'Checkpoint saved to {checkpoint_path}')\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    final_checkpoint_path = os.path.join(args.output_dir, 'model_final.pth')\n",
    "    torch.save({\n",
    "        'epoch': args.epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_epoch_loss,\n",
    "    }, final_checkpoint_path)\n",
    "    print(f'Final model saved to {final_checkpoint_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 학습 파라미터 설정 (argparse 대신 직접 설정)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.output_dir = '/content/drive/My Drive/TACO_Fasterrcnn_checkpoints'  # 'checkpoints' 폴더를 생성하거나 사용\n",
    "\n",
    "        # 폴더가 존재하지 않으면 생성\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        self.data_dir = data_path  # TACO 데이터셋 경로\n",
    "        self.num_rounds = 9            # 학습할 round 번호\n",
    "        self.batch_size = 2\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.005\n",
    "        self.save_freq = 1\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# 4. 출력 디렉토리 생성\n",
    "os.makedirs(args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthmera_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
